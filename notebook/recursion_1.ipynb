{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"recursion_1.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":["WVZgd3SV4vwH"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"4D-xh8jzDzar","colab_type":"code","outputId":"4dc4a6e7-591c-41f3-9da5-4a0045fb10a1","executionInfo":{"status":"ok","timestamp":1568037791038,"user_tz":-540,"elapsed":1053,"user":{"displayName":"soji okita","photoUrl":"","userId":"08576898653453722231"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/gdrive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tdrKDyTmHIaZ","colab_type":"code","outputId":"4808393f-50f4-43e2-c558-106b6b9c13cb","executionInfo":{"status":"ok","timestamp":1568037791043,"user_tz":-540,"elapsed":975,"user":{"displayName":"soji okita","photoUrl":"","userId":"08576898653453722231"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%cd '/gdrive/My Drive/'"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/gdrive/My Drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KwEH9yR4H51T","colab_type":"code","outputId":"58c3ffa0-54ba-490b-90ee-7f7d78cdbefb","executionInfo":{"status":"ok","timestamp":1568037794443,"user_tz":-540,"elapsed":4331,"user":{"displayName":"soji okita","photoUrl":"","userId":"08576898653453722231"}},"colab":{"base_uri":"https://localhost:8080/","height":252}},"source":["!ls -l analysis/recursion/data/"],"execution_count":0,"outputs":[{"output_type":"stream","text":["total 47869146\n","drwx------ 3 root root        4096 Sep  9 13:52 data_pkl\n","drwx------ 4 root root        4096 Sep  9 00:35 data_raw\n","-rw------- 1 root root    18449704 Sep  8 10:08 pixel_stats.csv.zip\n","-rw------- 1 root root       35620 Sep  8 10:08 recursion_dataset_license.pdf\n","-rw------- 1 root root      367018 Sep  8 10:08 sample_submission.csv\n","-rw------- 1 root root      114364 Sep  8 10:08 test_controls.csv\n","-rw------- 1 root root      574862 Sep  8 10:08 test.csv\n","-rw------- 1 root root 16872118408 Sep  8 10:23 test.zip\n","drwx------ 2 root root        4096 Sep  9 03:06 train2\n","-rw------- 1 root root      208866 Sep  8 10:08 train_controls.csv\n","-rw------- 1 root root     1203816 Jun 26 08:01 train.csv\n","-rw------- 1 root root      240888 Sep  8 10:08 train.csv.zip\n","-rw------- 1 root root 32124677223 Sep  8 10:26 train.zip\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UiAtWgdlzNof","colab_type":"code","colab":{}},"source":["# !git clone https://github.com/recursionpharma/rxrx1-utils"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8-fjJAl2whgb","colab_type":"code","colab":{}},"source":["# %cd analysis/recursion/data"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dKUoSKxf9M6V","colab_type":"code","colab":{}},"source":["# !mkdir /root/.kaggle/\n","# !cp /gdrive/My\\ Drive/analysis/kaggle/kaggle.json /root/.kaggle/"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9lTYCFZn70o0","colab_type":"code","colab":{}},"source":["# !kaggle competitions download -c recursion-cellular-image-classification -f train.zip -p train2.zip"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zvsBvShI_N9t","colab_type":"code","colab":{}},"source":["# !mkdir data_raw/train2"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kmeT4WMJa8l8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"622700fe-9aa2-42af-fc50-5b8c1eda9d52","executionInfo":{"status":"ok","timestamp":1568042566683,"user_tz":-540,"elapsed":1668913,"user":{"displayName":"soji okita","photoUrl":"","userId":"08576898653453722231"}}},"source":["!unzip -qo -d data_raw/train2 train2/train.zip "],"execution_count":27,"outputs":[{"output_type":"stream","text":["error:  zipfile read error\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"UvijwG1OGiGR","colab_type":"text"},"source":["## config"]},{"cell_type":"code","metadata":{"id":"vlE6Nvr8NCRs","colab_type":"code","colab":{}},"source":["%matplotlib inline\n","import matplotlib.pyplot as plt\n","import sys\n","import os\n","import glob\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import math\n","import cv2\n","\n","from tqdm import tqdm\n","import joblib\n","\n","from sklearn.model_selection import train_test_split"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"souTTfOqokij","colab_type":"code","colab":{}},"source":["import torch\n","import torchvision\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch import optim\n","\n","from torch.utils.data import Dataset, DataLoader"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"towMOqfFUryx","colab_type":"code","colab":{}},"source":["# !pip install pretrainedmodels\n","# import pretrainedmodels"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UYn21bWVQYcW","colab_type":"code","colab":{}},"source":["sys.path.append('analysis/recursion/src')\n","\n","from common.logger import create_logger, get_logger\n","from model.loss import ArcMarginProduct\n","from common.util import str_stats\n","from model.metrics import AverageMeter\n","from model.model_util import save_checkpoint, load_checkpoint"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bzPFgjjzzZVB","colab_type":"code","outputId":"41d5a829-4bf8-46d0-a5b2-0c332ef895da","executionInfo":{"status":"error","timestamp":1568037795669,"user_tz":-540,"elapsed":5340,"user":{"displayName":"soji okita","photoUrl":"","userId":"08576898653453722231"}},"colab":{"base_uri":"https://localhost:8080/","height":318}},"source":["# sys.path.append('analysis/recursion/src/rxrx1-utils')\n","# import rxrx.io as rio"],"execution_count":0,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-0079424f7630>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'analysis/recursion/src/rxrx1-utils'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mrxrx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mrio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'rxrx'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"cell_type":"code","metadata":{"id":"vDRrD5OkGueC","colab_type":"code","colab":{}},"source":["IMG_SIZE = (512, 512)\n","INPUT_SIZE = (256, 256)\n","TEST_INPUT_SIZE = (256, 256) #(1024, 1024)\n","\n","INPUT = 'analysis/recursion/data/'\n","TRAIN_PATH = os.path.join(INPUT, 'train.csv')\n","TEST_PATH = os.path.join(INPUT, 'test.csv')\n","TRAIN_IMG_PATH = os.path.join(INPUT, 'data_raw', 'train2')\n","TEST_IMG_PATH = os.path.join(INPUT, 'data_raw', 'test')\n","\n","N_SAMPLES = 5\n","RUN_TTA = False"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"1EAR0MxPQ8zV","colab":{}},"source":["N_CLASSES = 1108\n","\n","BATCH_SIZE_TRAIN = 32\n","BATCH_SIZE_TEST = 128\n","NUM_WORKERS = 8\n","PRINT_FREQ = 10\n","ITER_PER_CYCLE = 20\n","EPOCHS = 5 + ITER_PER_CYCLE * 4\n","\n","ADAM_LR = 5e-4\n","SGD_LR = 1e-3\n","MIN_LR = 1e-3\n","MOMENTUM = 0.9\n","WEIGHT_DECAY = 1e-4\n","\n","USE_PRETRAINED = False\n","PRETRAIN_PATH = 'analysis/recursion/models/res34_unet_1/best_model.pth'\n","\n","DROPOUT_RATE = 0.2\n","LATENT_DIM = 512\n","TEMPERATURE = 60\n","MARGIN = 0.5"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"q5GZXQ7PMYaH","colab_type":"code","outputId":"50c7f2f8-2c89-49ed-9f25-6eeb59950092","executionInfo":{"status":"ok","timestamp":1568037826293,"user_tz":-540,"elapsed":2409,"user":{"displayName":"soji okita","photoUrl":"","userId":"08576898653453722231"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["create_logger('recursion.log')\n","get_logger().info('start kernel')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[INFO]2019-09-09 14:03:48,136:main:start kernel\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"VA9FY8gYWTE_","colab_type":"text"},"source":["# eda"]},{"cell_type":"code","metadata":{"id":"Uj5a7Q-vWU6C","colab_type":"code","colab":{}},"source":["# df_train = pd.read_csv(TRAIN_PATH)\n","# df_train.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yWC3YBCN08KT","colab_type":"code","colab":{}},"source":["# t = rio.load_site('train', 'RPE-05', 3, 'D19', 2)\n","# t.shape"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ys3cnzES12jU","colab_type":"code","colab":{}},"source":["'''\n","def load_site(dataset,\n","              experiment,\n","              plate,\n","              well,\n","              site,\n","              channels=DEFAULT_CHANNELS,\n","              base_path=DEFAULT_IMAGES_BASE_PATH):\n","'''"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6rU670vH2fAV","colab_type":"text"},"source":["# helper_func"]},{"cell_type":"code","metadata":{"id":"BHFmEgN-2ewQ","colab_type":"code","colab":{}},"source":["def train_valid_split_v1(df, valid_ratio):\n","    df_trn, df_val = train_test_split(df, \n","                                       stratify=df['sirna'], \n","                                       test_size=valid_ratio, \n","                                       random_state=2019, \n","                                       shuffle=True)\n","    return df_trn, df_val"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SRPrLil8WWaW","colab_type":"text"},"source":["# metrics"]},{"cell_type":"code","metadata":{"id":"qgwRKGO7WZI1","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FrKCzzt0WZgc","colab_type":"text"},"source":["# dataset"]},{"cell_type":"code","metadata":{"id":"ocVf9q5kWdP3","colab_type":"code","colab":{}},"source":["import cv2\n","import albumentations as A\n","import albumentations.pytorch as ATorch\n","\n","alb_trn_trnsfms = A.Compose([\n","    # A.CLAHE(p=1),\n","    A.Rotate(limit=10, p=1),\n","    # A.RandomSizedCrop((IMG_SIZE[0]-32, IMG_SIZE[0]-10), *INPUT_SIZE),    \n","    A.RandomCrop(*INPUT_SIZE),\n","    # A.HueSaturationValue(val_shift_limit=20, p=0.5),\n","    # A.RandomBrightnessContrast(),        \n","    # A.Resize(*INPUT_SIZE),    \n","    A.Normalize(\n","        mean=[0.5, 0.5, 0.5, 0.5, 0.5, 0.5],\n","        std=[0.5, 0.5, 0.5, 0.5, 0.5, 0.5],\n","    ),\n","    ATorch.transforms.ToTensor()\n","], p=1)\n","    \n","'''\n","    A.Normalize(\n","        mean=[0.485, 0.456, 0.406, 0.485, 0.456, 0.406],\n","        std=[0.229, 0.224, 0.225, 0.229, 0.224, 0.225],\n","        always_apply=False\n","    ),\n","'''\n","\n","\n","alb_val_trnsfms = A.Compose([\n","    # A.CLAHE(p=1),\n","    # A.Resize(*INPUT_SIZE),\n","    A.CenterCrop(*INPUT_SIZE),\n","    A.Normalize(\n","        mean=[0.5, 0.5, 0.5, 0.5, 0.5, 0.5],\n","        std=[0.5, 0.5, 0.5, 0.5, 0.5, 0.5],  \n","    ),\n","    ATorch.transforms.ToTensor()\n","], p=1)\n","\n","alb_tst_trnsfms = A.Compose([\n","    # A.CLAHE(),\n","    A.Resize(*TEST_INPUT_SIZE),\n","    A.Normalize(\n","        mean=[0.5, 0.5, 0.5, 0.5, 0.5, 0.5],\n","        std=[0.5, 0.5, 0.5, 0.5, 0.5, 0.5],          \n","    ),\n","    ATorch.transforms.ToTensor()\n","], p=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AK8FVxSHaESO","colab_type":"code","colab":{}},"source":["class CellerDataset(Dataset):    \n","    target_name = 'sirna'\n","    image_name = ''\n","    id_name = 'id_code'\n","    site = 1\n","\n","    def __init__(self, df, image_dir, transform, mode):\n","        self.df_org = df.copy()        \n","        self.image_dir = image_dir        \n","        self.transform = transform\n","        self.mode = mode\n","\n","        # Random Selection\n","        if mode == 'train':\n","            self.update()\n","        elif mode in ['valid', 'predict']:\n","            self.df_selected = self.df_org\n","        else:\n","            raise ValueError('Unexpected mode: %s' % mode)\n","    \n","    def __len__(self):\n","        return self.df_selected.shape[0]\n","    \n","    def __getitem__(self, idx):        \n","        # image_names = get_image_name(self.df_selected, idx, self.site)\n","        # image = self.__load_image(image_names)\n","        image = self.__load_image_with_rxrx(self.df_selected, idx)\n","        if self.mode in ['train', 'valid']:\n","            label =  self.df_selected.iloc[idx][self.target_name]            \n","        elif self.mode == 'predict':\n","            label = -1\n","        return image, torch.Tensor([label])\n","    \n","    def __load_image_with_rxrx(self, df, idx):\n","        dataset = 'train' if self.mode in ['train', 'valid'] else 'test'\n","\n","        rcd = df.iloc[idx]\n","        experiment = rcd['experiment']\n","        plate = rcd['plate']\n","        well = rcd['well']\n","        image = rio.load_site('train', experiment, plate, well, 1)\n","        \n","        augmented = self.transform(image=image)\n","        image = augmented['image']\n","        return image\n","\n","    def __load_image(self, image_names):\n","        \"\"\"\n","        Parameters\n","        ----------\n","        image_names: list of str\n","        \"\"\"\n","\n","        images = []\n","        for image_name in image_names:\n","            image_path = os.path.join(self.image_dir, image_name)\n","            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n","            \n","            if image is None:\n","                raise ValueError('Not found image: %s' % image_path)\n","            images.append(image)\n","        images = np.stack(images, axis=2)\n","        \n","        augmented = self.transform(image=images)\n","        image = augmented['image']\n","        return image\n","\n","    def update(self):\n","        if self.mode != 'train':\n","            raise ValueError('CellerDataset is not train mode.')\n","        self.df_selected = self.random_selection(N_SAMPLES)\n","\n","    def random_selection(self, n_samples):                        \n","        g = self.df_org.groupby(self.target_name)[self.id_name]\n","        # selected = []\n","        # selected.append(np.random.choice(g.get_group(0).tolist(), n_samples, replace=False))\n","        # selected.append(np.random.choice(g.get_group(1).tolist(), n_samples, replace=False))\n","        selected = [np.random.choice(g.get_group(i).tolist(), n_samples, replace=False) for i in range(N_CLASSES)]\n","        selected = np.concatenate(selected, axis=0)\n","\n","        df_new = pd.DataFrame({self.id_name: selected})\n","        df_new = df_new.merge(self.df_org, on=self.id_name, how='left')\n","        get_logger().info('num of selected_images: %d' % len(df_new))\n","\n","        return df_new\n","\n","\n","def get_image_name(df, idx, site):\n","    \"\"\"\n","    Returns\n","    -------\n","    file_paths: list\n","        image path list of 6 channels\n","    \"\"\"\n","    rcd = df.iloc[idx]\n","    experiment = rcd['experiment']\n","    plate = 'Plate%d' % rcd['plate']\n","    well = rcd['well']\n","\n","    file_names = ['%s_s%d_w%d.png' % (well, site, i+1) for i in range(6)]\n","    file_paths = [os.path.join(experiment, plate, file_name) for file_name in file_names]\n","    return file_paths\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_OIcwTZeWd1V","colab_type":"text"},"source":["# model/loss"]},{"cell_type":"code","metadata":{"id":"o8Muo8yq489B","colab_type":"code","colab":{}},"source":["class ResNet(nn.Module):\n","    def __init__(self, dropout_rate, latent_dim, temperature, m):\n","        super(ResNet, self).__init__()\n","        # self.resnet = torchvision.models.resnet50(pretrained=True)\n","        self.resnet = torchvision.models.resnet34(pretrained=True)\n","        # self.resnet = torchvision.models.resnet18(pretrained=True)\n","        n_out_channels = 512  # resnet18, 34: 512, resnet50: 512*4\n","\n","        conv1 = self.resnet.conv1\n","        self.resnet.conv1 = nn.Conv2d(in_channels=6,\n","                                      out_channels=conv1.out_channels,\n","                                      kernel_size=conv1.kernel_size,\n","                                      stride=conv1.stride,\n","                                      padding=conv1.padding,\n","                                      bias=conv1.bias)\n","\n","        # copy pretrained weights\n","        self.resnet.conv1.weight.data[:,:3,:,:] = conv1.weight.data\n","        self.resnet.conv1.weight.data[:,3:,:,:] = conv1.weight.data\n","\n","        '''\n","        trained_kernel = self.resnet.conv1.weight\n","        new_conv = nn.Conv2d(6, 64, kernel_size=7, stride=2, padding=3, bias=False)\n","        with torch.no_grad():\n","            new_conv.weight[:,:] = torch.stack([torch.mean(trained_kernel, 1)]*6, dim=1)\n","        self.resnet.conv1 = new_conv\n","        '''\n","\n","        # FC        \n","        self.norm1 = nn.BatchNorm1d(n_out_channels)\n","        self.drop1 = nn.Dropout(dropout_rate)\n","        # FC\n","        self.fc = nn.Linear(n_out_channels, latent_dim)\n","        self.norm2 = nn.BatchNorm1d(latent_dim)\n","        self.arc = ArcMarginProduct(latent_dim, N_CLASSES, s=temperature, m=m, easy_margin=False)\n","\n","    def forward(self, x, label=None):\n","        x = self.resnet.conv1(x)\n","        x = self.resnet.bn1(x)\n","        x = self.resnet.relu(x)\n","        x = self.resnet.maxpool(x)\n","\n","        x = self.resnet.layer1(x)\n","        x = self.resnet.layer2(x)\n","        x = self.resnet.layer3(x)\n","        x = self.resnet.layer4(x)\n","        \n","        # GAP\n","        x = F.adaptive_avg_pool2d(x, (1, 1))\n","        x = x.view(x.size(0), -1)\n","        x = self.norm1(x)\n","        x = F.relu(x)\n","        x = self.drop1(x)\n","        # FC\n","        x = self.fc(x)\n","        # x = self.norm2(x)\n","        # Arc\n","        x = self.arc(x, label)\n","\n","        return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BVgaB1yF4yui","colab_type":"code","colab":{}},"source":["class SEResNet(nn.Module):\n","    def __init__(self, dropout_rate, latent_dim, temperature, m):\n","        super(SEResNet, self).__init__()\n","\n","        senet = pretrainedmodels.__dict__['se_resnext50_32x4d'](\n","            num_classes=1000, pretrained='imagenet')\n","        self.layer0 = senet.layer0\n","        self.layer1 = senet.layer1\n","        self.layer2 = senet.layer2\n","        self.layer3 = senet.layer3\n","        self.layer4 = senet.layer4\n","\n","        self.norm1 = nn.BatchNorm1d(512*4)\n","        self.drop1 = nn.Dropout(dropout_rate)\n","        # FC\n","        self.fc = nn.Linear(512*4, latent_dim)        \n","        # self.norm2 = nn.BatchNorm1d(output_neurons)\n","        self.arc = ArcMarginProduct(latent_dim, 2, s=temperature, m=m, easy_margin=False)\n","\n","    def forward(self, x, label=None):\n","        x = self.layer0(x)\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","\n","        # GAP\n","        x = F.adaptive_avg_pool2d(x, (1, 1))\n","        x = x.view(x.size(0), -1)\n","        x = self.norm1(x)\n","        x = F.relu(x)\n","        x = self.drop1(x)\n","        # FC\n","        x = self.fc(x)\n","        # x = self.norm2(x)\n","        # Arc\n","        x = self.arc(x, label)\n","\n","        return x\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WVZgd3SV4vwH","colab_type":"text"},"source":["## warmup"]},{"cell_type":"code","metadata":{"id":"AbN_Q3_7aktU","colab_type":"code","colab":{}},"source":["from torch.optim.lr_scheduler import _LRScheduler\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","\n","\n","class GradualWarmupScheduler(_LRScheduler):\n","    \"\"\" Gradually warm-up(increasing) learning rate in optimizer.\n","    Proposed in 'Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour'.\n","\n","    Args:\n","        optimizer (Optimizer): Wrapped optimizer.\n","        multiplier: target learning rate = base lr * multiplier\n","        total_epoch: target learning rate is reached at total_epoch, gradually\n","        after_scheduler: after target_epoch, use this scheduler(eg. ReduceLROnPlateau)\n","    \"\"\"\n","\n","    def __init__(self, optimizer, multiplier, total_epoch, after_scheduler=None):\n","        self.multiplier = multiplier\n","        if self.multiplier <= 1.:\n","            raise ValueError('multiplier should be greater than 1.')\n","        self.total_epoch = total_epoch\n","        self.after_scheduler = after_scheduler\n","        self.finished = False\n","        super().__init__(optimizer)\n","\n","    def get_lr(self):\n","        if self.last_epoch > self.total_epoch:\n","            if self.after_scheduler:\n","                if not self.finished:\n","                    self.after_scheduler.base_lrs = [base_lr * self.multiplier for base_lr in self.base_lrs]\n","                    self.finished = True\n","                return self.after_scheduler.get_lr()\n","            return [base_lr * self.multiplier for base_lr in self.base_lrs]\n","\n","        return [base_lr * ((self.multiplier - 1.) * self.last_epoch / self.total_epoch + 1.) for base_lr in self.base_lrs]\n","\n","    def step_ReduceLROnPlateau(self, metrics, epoch=None):\n","        if epoch is None:\n","            epoch = self.last_epoch + 1\n","        self.last_epoch = epoch if epoch != 0 else 1  # ReduceLROnPlateau is called at the end of epoch, whereas others are called at beginning\n","        if self.last_epoch <= self.total_epoch:\n","            warmup_lr = [base_lr * ((self.multiplier - 1.) * self.last_epoch / self.total_epoch + 1.) for base_lr in self.base_lrs]\n","            for param_group, lr in zip(self.optimizer.param_groups, warmup_lr):\n","                param_group['lr'] = lr\n","        else:\n","            if epoch is None:\n","                self.after_scheduler.step(metrics, None)\n","            else:\n","                self.after_scheduler.step(metrics, epoch - self.total_epoch)\n","\n","    def step(self, epoch=None, metrics=None):\n","        if type(self.after_scheduler) != ReduceLROnPlateau:\n","            if self.finished and self.after_scheduler:\n","                if epoch is None:\n","                    self.after_scheduler.step(None)\n","                else:\n","                    self.after_scheduler.step(epoch - self.total_epoch)\n","            else:\n","                return super(GradualWarmupScheduler, self).step(epoch)\n","        else:\n","            self.step_ReduceLROnPlateau(metrics, epoch)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3NSUIOd5WjFK","colab_type":"text"},"source":["# train"]},{"cell_type":"code","metadata":{"id":"T4KSvLWY9Lnf","colab_type":"code","colab":{}},"source":["from model.metrics import accuracy\n","\n","def train_one_epoch(epoch,\n","                        model,\n","                        loader,\n","                        criterion,\n","                        optimizer):\n","    loss_meter = AverageMeter()\n","    top1_meter = AverageMeter()\n","    top5_meter = AverageMeter()\n","\n","    get_logger().info('[Start] epoch: %d' % epoch)\n","    get_logger().info('lr: %f' %\n","                      optimizer.state_dict()['param_groups'][0]['lr'])\n","    loader.dataset.update()\n","    # train phase\n","    model.train()\n","    for i, data in enumerate(tqdm(loader)):\n","        img, label = data\n","        img, label = img.cuda(), label.cuda().long()\n","        with torch.set_grad_enabled(True):        \n","            logit = model(img, label)\n","            loss = criterion(logit, label.squeeze())\n","\n","            # backward\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            loss_meter.update(loss.item(), img.size(0))            \n","            score_top1, score_top5 = accuracy(logit.detach(), label.detach(), topk=(1, 5))\n","            top1_meter.update(score_top1.item(), img.size(0))\n","            top5_meter.update(score_top5.item(), img.size(0))\n","\n","        # print\n","        if i % PRINT_FREQ == 0:\n","            logit_cpu = logit.view(img.size(0), -1).detach().cpu()\n","            get_logger().info('\\n' + str_stats(logit_cpu[0].numpy()))  \n","            softmaxed = F.softmax(logit_cpu, dim=1)       \n","            get_logger().info('\\n' + str_stats(softmaxed[0].numpy()))\n","            get_logger().info('train: %d loss: %f top1: %f top5: %f (just now)' %\n","                              (i, loss_meter.val, top1_meter.val, top5_meter.val))\n","            get_logger().info('train: %d loss: %f top1: %f top5: %f' %\n","                              (i, loss_meter.avg, top1_meter.avg, top5_meter.avg))\n","            \n","    get_logger().info(\"Epoch %d/%d train loss %f top1 %f top5 %f\" \n","                      % (epoch, EPOCHS, loss_meter.avg, top1_meter.avg, top5_meter.avg))\n","\n","    return loss_meter.avg, top1_meter.avg, top5_meter.avg\n","\n","def validate_one_epoch(epoch,\n","                        model,                   \n","                        loader,\n","                        criterion):\n","    loss_meter = AverageMeter()\n","    top1_meter = AverageMeter()\n","    top5_meter = AverageMeter()   \n","\n","    # validate phase\n","    model.eval()\n","    for i, data in enumerate(tqdm(loader)):\n","        img, label = data\n","        img, label = img.cuda(), label.cuda().long()\n","        with torch.no_grad():\n","            logit = model(img)           \n","\n","            loss = criterion(logit, label.squeeze())\n","            loss_meter.update(loss.item(), img.size(0))\n","            score_top1, score_top5 = accuracy(logit.detach(), label, topk=(1, 5))\n","            top1_meter.update(score_top1.item(), img.size(0))        \n","            top5_meter.update(score_top5.item(), img.size(0))        \n","\n","    get_logger().info(\"Epoch %d/%d valid loss %f top1 %f top5 %f\" \n","                      % (epoch, EPOCHS, loss_meter.avg, top1_meter.avg, top5_meter.avg))\n","\n","    return loss_meter.avg, top1_meter.avg, top5_meter.avg"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lXv5IGUTFHOo","colab_type":"code","colab":{}},"source":["from model.loss import FocalLoss\n","\n","def train():\n","    # Load csv\n","    df_train = pd.read_csv(TRAIN_PATH)        \n","    df_trn, df_val = train_valid_split_v1(df_train, valid_ratio=0.05)\n","    get_logger().info('train size: %d valid size: %d' % (len(df_trn), len(df_val)))\n","\n","    train_dataset = CellerDataset(df_trn, TRAIN_IMG_PATH, alb_trn_trnsfms, mode='train')\n","    train_loader = DataLoader(train_dataset,\n","                                batch_size=BATCH_SIZE_TRAIN,\n","                                num_workers=NUM_WORKERS,\n","                                pin_memory=True,\n","                                drop_last=True,\n","                                shuffle=True\n","                                )\n","    valid_dataset = CellerDataset(df_val, TRAIN_IMG_PATH, alb_val_trnsfms, mode='valid')\n","    valid_loader = DataLoader(valid_dataset,\n","                              batch_size=BATCH_SIZE_TRAIN,\n","                              num_workers=NUM_WORKERS,\n","                              pin_memory=True,\n","                              drop_last=False,\n","                              shuffle=False\n","                              )    \n","    model, criterion, optimizer, scheduler = init_model()\n","    start_epoch = 0\n","    if USE_PRETRAINED:\n","        start_epoch, model, optimizer, scheduler, _ = load_checkpoint(model, optimizer, scheduler, CLF_PRETRAIN_PATH)\n","\n","    get_logger().info('[Start] Recursion Celler Training')\n","    best_score = 0\n","    train_history = {'loss': [], 'top1': [], 'top5': []}\n","    valid_history = {'loss': [], 'top1': [], 'top5': []}\n","    for epoch in range(start_epoch + 1, EPOCHS + 1):\n","        train_loss, train_top1, train_top5 = train_one_epoch(epoch, model, train_loader, criterion, optimizer)\n","        valid_loss, valid_top1, valid_top5 = validate_one_epoch(epoch, model, valid_loader, criterion)\n","\n","        train_history['loss'].append(train_loss)\n","        train_history['top1'].append(train_top1)\n","        train_history['top5'].append(train_top1)\n","        valid_history['loss'].append(valid_loss)\n","        valid_history['top1'].append(valid_top1)\n","        valid_history['top5'].append(valid_top5)\n","        \n","        valid_score = valid_top1\n","        is_best = valid_score > best_score\n","        if is_best:\n","            best_score = valid_score\n","        get_logger().info('best score (%f) at epoch (%d)' % (valid_score, epoch))\n","        save_checkpoint({\n","            'epoch': epoch,\n","            'state_dict': model.state_dict(),            \n","            'optimizer': optimizer.state_dict(),\n","            'scheduler': scheduler.state_dict()\n","        }, is_best)\n","        # move scheduler.step to here\n","        scheduler.step()\n","\n","    return train_history, valid_history"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KoYQ1yQs-BLz","colab_type":"code","colab":{}},"source":["def init_model():\n","    torch.backends.cudnn.benchmark = True\n","    get_logger().info('Initializing classification model...')\n","    model = ResNet(dropout_rate=DROPOUT_RATE, \n","                   latent_dim=LATENT_DIM, \n","                   temperature=TEMPERATURE,\n","                   m=MARGIN).cuda()\n","    # model = SEResNet(dropout_rate=0.3, latent_dim=512, temperature=1.0, m=MARGIN).cuda()\n","    criterion = FocalLoss(gamma=2).cuda()    \n","    '''\n","    optimizer = torch.optim.SGD([{'params': model.parameters()}],\n","                                lr=SGD_LR, \n","                                momentum=MOMENTUM,\n","                                weight_decay=WEIGHT_DECAY)\n","    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, EPOCHS, MIN_LR)\n","    '''\n","    optimizer = optim.Adam([{'params': model.parameters()}], lr=ADAM_LR)\n","    mile_stones = [10, 20, 30, 40]\n","    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, mile_stones, gamma=0.5, last_epoch=-1)                    \n","    \n","    return model, criterion, optimizer, scheduler"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bBAu3EBSdeGe","colab_type":"text"},"source":["# main"]},{"cell_type":"code","metadata":{"id":"acxwJOk-dfBN","colab_type":"code","outputId":"92732880-1e4a-4354-b292-254b0b56ffb2","executionInfo":{"status":"error","timestamp":1568031301831,"user_tz":-540,"elapsed":153358,"user":{"displayName":"soji okita","photoUrl":"","userId":"08576898653453722231"}},"colab":{"base_uri":"https://localhost:8080/","height":812}},"source":["train()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[INFO]2019-09-09 12:12:40,176:main:train size: 34689 valid size: 1826\n","[INFO]2019-09-09 12:12:40,612:main:num of selected_images: 5540\n","[INFO]2019-09-09 12:12:40,615:main:Initializing classification model...\n","[INFO]2019-09-09 12:12:44,286:main:[Start] Recursion Celler Training\n","[INFO]2019-09-09 12:12:44,289:main:[Start] epoch: 1\n","[INFO]2019-09-09 12:12:44,292:main:lr: 0.000500\n","[INFO]2019-09-09 12:12:44,658:main:num of selected_images: 5540\n","  0%|          | 0/173 [00:00<?, ?it/s][INFO]2019-09-09 12:13:51,054:main:\n","    count      mean       std  ...       50%       75%       max\n","0  1108.0 -0.026315  2.744862  ...  0.094188  1.696812  9.360255\n","\n","[1 rows x 8 columns]\n","[INFO]2019-09-09 12:13:51,159:main:\n","    count      mean       std  ...       50%       75%       max\n","0  1108.0  0.000903  0.010581  ...  0.000028  0.000137  0.291325\n","\n","[1 rows x 8 columns]\n","[INFO]2019-09-09 12:13:51,267:main:train: 0 loss: 38.936111 top1: 0.000000 top5: 0.000000 (just now)\n","[INFO]2019-09-09 12:13:51,275:main:train: 0 loss: 38.936111 top1: 0.000000 top5: 0.000000\n","  6%|▌         | 10/173 [02:06<40:05, 14.76s/it][INFO]2019-09-09 12:14:51,223:main:\n","    count      mean       std       min       25%       50%       75%      max\n","0  1108.0 -1.653966  2.672726 -26.59046 -3.409239 -1.597343  0.041544  6.48376\n","[INFO]2019-09-09 12:14:51,266:main:\n","    count      mean       std  ...       50%      75%       max\n","0  1108.0  0.000903  0.005548  ...  0.000045  0.00023  0.144287\n","\n","[1 rows x 8 columns]\n","[INFO]2019-09-09 12:14:51,269:main:train: 10 loss: 39.809048 top1: 0.000000 top5: 0.000000 (just now)\n","[INFO]2019-09-09 12:14:51,270:main:train: 10 loss: 39.039235 top1: 0.000000 top5: 0.000000\n","  9%|▉         | 16/173 [02:08<05:35,  2.14s/it]"],"name":"stderr"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-32-2da0ffaf5447>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-30-886ccc1f5118>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mvalid_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'top1'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'top5'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_epoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_top1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_top5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_top1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_top5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-29-621ad41c51bd>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(epoch, model, loader, criterion, optimizer)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# train phase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tqdm/_tqdm.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    977\u001b[0m \"\"\", fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    980\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    574\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_batch\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    171\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"N3LUicw4fMM6","colab_type":"code","colab":{}},"source":["# df_train = pd.read_csv(TRAIN_PATH)\n","# df_trn, df_val = train_valid_split_v1(df_train, valid_ratio=0.1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lxuUk_KffDkB","colab_type":"code","colab":{}},"source":["# dataset = CellerDataset(df_trn, TRAIN_IMG_PATH, alb_trn_trnsfms, mode='train')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_kiQfHto52bp","colab_type":"code","colab":{}},"source":["'''\n","fig, axes = plt.subplots(2, 3, figsize=(24, 16))\n","\n","for i, ax in enumerate(axes.flatten()):\n","    # ax.axis('off')\n","    ax.set_title('channel {}'.format(i + 1))\n","    _ = ax.imshow(img[i, :, :], cmap='gray')\n","'''"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bxMreFfcfaK-","colab_type":"code","colab":{}},"source":["# img.size()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YS9B4CAKfm_r","colab_type":"code","colab":{}},"source":["# print(str_stats(img.numpy().reshape(-1)))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3qmWjpJCoLhM","colab_type":"code","colab":{}},"source":["# less analysis/recursion/data/train.csv"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TxSZ0MbdoQEm","colab_type":"code","colab":{}},"source":["# %cd analysis/recursion/data"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wn_p__ahpV_X","colab_type":"code","colab":{}},"source":["# !ls -l"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7RgPIwmevTbu","colab_type":"code","colab":{}},"source":["# !chmod 700 *"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iEJBNxtmpWoC","colab_type":"code","colab":{}},"source":["# !unzip train.csv.zip"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XFqdUpKSqReY","colab_type":"code","outputId":"5e818ace-7f01-4e01-ee0b-143167931b08","executionInfo":{"status":"ok","timestamp":1568037830846,"user_tz":-540,"elapsed":1075,"user":{"displayName":"soji okita","photoUrl":"","userId":"08576898653453722231"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%cd analysis/recursion/data"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/gdrive/My Drive/analysis/recursion/data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Jjhom2lI9G5i","colab_type":"code","outputId":"515404db-9000-46ce-c1a0-5bd0db05b7cd","executionInfo":{"status":"ok","timestamp":1568037832396,"user_tz":-540,"elapsed":1038,"user":{"displayName":"soji okita","photoUrl":"","userId":"08576898653453722231"}},"colab":{"base_uri":"https://localhost:8080/","height":195}},"source":["df_train = pd.read_csv('train.csv')\n","df_train.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id_code</th>\n","      <th>experiment</th>\n","      <th>plate</th>\n","      <th>well</th>\n","      <th>sirna</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>HEPG2-01_1_B03</td>\n","      <td>HEPG2-01</td>\n","      <td>1</td>\n","      <td>B03</td>\n","      <td>513</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>HEPG2-01_1_B04</td>\n","      <td>HEPG2-01</td>\n","      <td>1</td>\n","      <td>B04</td>\n","      <td>840</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>HEPG2-01_1_B05</td>\n","      <td>HEPG2-01</td>\n","      <td>1</td>\n","      <td>B05</td>\n","      <td>1020</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>HEPG2-01_1_B06</td>\n","      <td>HEPG2-01</td>\n","      <td>1</td>\n","      <td>B06</td>\n","      <td>254</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>HEPG2-01_1_B07</td>\n","      <td>HEPG2-01</td>\n","      <td>1</td>\n","      <td>B07</td>\n","      <td>144</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          id_code experiment  plate well  sirna\n","0  HEPG2-01_1_B03   HEPG2-01      1  B03    513\n","1  HEPG2-01_1_B04   HEPG2-01      1  B04    840\n","2  HEPG2-01_1_B05   HEPG2-01      1  B05   1020\n","3  HEPG2-01_1_B06   HEPG2-01      1  B06    254\n","4  HEPG2-01_1_B07   HEPG2-01      1  B07    144"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"FNY0ADbnBjf5","colab_type":"code","colab":{}},"source":["def load_6_images(dir_name, image_names):\n","    images = []\n","    for image_name in image_names:\n","        image_path = os.path.join('data_raw', 'train2', dir_name, image_name)\n","        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n","            \n","        if image is None:\n","            raise ValueError('Not found image: %s' % image_path)\n","        images.append(image)\n","    images = np.stack(images, axis=2)\n","    return images"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ObQYur4z94or","colab_type":"code","colab":{}},"source":["def convert_png(rcd):\n","    experiment = rcd['experiment']\n","    plate = 'Plate%d' % rcd['plate']\n","    well = rcd['well']\n","    dir_name = os.path.join(experiment, plate)    \n","\n","    sites = [1, 2]\n","    for site in sites:\n","        file_names = ['%s_s%d_w%d.png' % (well, site, i+1) for i in range(6)]\n","        \n","        dest_file_name = '%s_s%d.pkl' % (well, site)\n","        dest_dir_name = os.path.join('data_pkl', 'train', dir_name)\n","        dest_file_path = os.path.join(dest_dir_name, dest_file_name)\n","        # make dir\n","        os.makedirs(dest_dir_name, exist_ok=True)\n","\n","        image = load_6_images(dir_name, file_names)\n","\n","        # print('write to %s' % dest_file_path)\n","        joblib.dump(image, dest_file_path)\n","\n","    return 0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hWHrZknLSmsb","colab_type":"code","colab":{}},"source":["# 12738/36515"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"le_4Bblz9hY6","colab_type":"code","outputId":"76b7ff6c-8a7c-4ab5-91a3-24e143e507bd","executionInfo":{"status":"error","timestamp":1568037837933,"user_tz":-540,"elapsed":1065,"user":{"displayName":"soji okita","photoUrl":"","userId":"08576898653453722231"}},"colab":{"base_uri":"https://localhost:8080/","height":325}},"source":["_ = [convert_png(df_train.iloc[i]) for i in tqdm(range(12737, len(df_train)))]"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\r  0%|          | 0/23778 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-9a37ee6ffb8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconvert_png\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12737\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-24-9a37ee6ffb8d>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconvert_png\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12737\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-23-c1794acd8611>\u001b[0m in \u001b[0;36mconvert_png\u001b[0;34m(rcd)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdest_dir_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_6_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# print('write to %s' % dest_file_path)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-22-d556c7eda409>\u001b[0m in \u001b[0;36mload_6_images\u001b[0;34m(dir_name, image_names)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Not found image: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Not found image: data_raw/train2/HUVEC-05/Plate3/B04_s1_w1.png"]}]},{"cell_type":"code","metadata":{"id":"JWGCCAu3TKaX","colab_type":"code","colab":{}},"source":["!ls data_raw/train2/HUVEC-05/Plate2"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_cV4xh_RG_hT","colab_type":"code","outputId":"c66f4ceb-85b5-4cb7-c228-698064241303","executionInfo":{"status":"ok","timestamp":1568034454210,"user_tz":-540,"elapsed":616,"user":{"displayName":"soji okita","photoUrl":"","userId":"08576898653453722231"}},"colab":{"base_uri":"https://localhost:8080/","height":195}},"source":["df_train.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id_code</th>\n","      <th>experiment</th>\n","      <th>plate</th>\n","      <th>well</th>\n","      <th>sirna</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>HEPG2-01_1_B03</td>\n","      <td>HEPG2-01</td>\n","      <td>1</td>\n","      <td>B03</td>\n","      <td>513</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>HEPG2-01_1_B04</td>\n","      <td>HEPG2-01</td>\n","      <td>1</td>\n","      <td>B04</td>\n","      <td>840</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>HEPG2-01_1_B05</td>\n","      <td>HEPG2-01</td>\n","      <td>1</td>\n","      <td>B05</td>\n","      <td>1020</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>HEPG2-01_1_B06</td>\n","      <td>HEPG2-01</td>\n","      <td>1</td>\n","      <td>B06</td>\n","      <td>254</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>HEPG2-01_1_B07</td>\n","      <td>HEPG2-01</td>\n","      <td>1</td>\n","      <td>B07</td>\n","      <td>144</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          id_code experiment  plate well  sirna\n","0  HEPG2-01_1_B03   HEPG2-01      1  B03    513\n","1  HEPG2-01_1_B04   HEPG2-01      1  B04    840\n","2  HEPG2-01_1_B05   HEPG2-01      1  B05   1020\n","3  HEPG2-01_1_B06   HEPG2-01      1  B06    254\n","4  HEPG2-01_1_B07   HEPG2-01      1  B07    144"]},"metadata":{"tags":[]},"execution_count":63}]},{"cell_type":"code","metadata":{"id":"Da4komKzIvev","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}